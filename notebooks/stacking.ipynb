{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords and labels\n",
    "\n",
    "data = {\n",
    "    \"train\": pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\"../data/wine_keywords_train.csv\"),\n",
    "            pd.read_csv(\"../data/wine_keywords_val.csv\"),\n",
    "        ]\n",
    "    ).dropna(),\n",
    "    \"test\": pd.read_csv(\"../data/wine_keywords_test.csv\").dropna(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>region_variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>core adequate acidity moderate extraction medi...</td>\n",
       "      <td>France-Languedoc-Roussillon:Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complexity varietal character black plum light...</td>\n",
       "      <td>US-California:Merlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rhubarb cranberry fruit red apple light simple...</td>\n",
       "      <td>US-Oregon:Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impressive fullness ripeness black cherry leat...</td>\n",
       "      <td>Italy-Veneto:Corvina, Rondinella, Molinara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dusty tones mineral saffron pollen concentrate...</td>\n",
       "      <td>Germany-Mosel:Riesling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            keywords  \\\n",
       "0  core adequate acidity moderate extraction medi...   \n",
       "1  complexity varietal character black plum light...   \n",
       "2  rhubarb cranberry fruit red apple light simple...   \n",
       "3  impressive fullness ripeness black cherry leat...   \n",
       "4  dusty tones mineral saffron pollen concentrate...   \n",
       "\n",
       "                                   region_variety  \n",
       "0  France-Languedoc-Roussillon:Cabernet Sauvignon  \n",
       "1                            US-California:Merlot  \n",
       "2                            US-Oregon:Pinot Noir  \n",
       "3      Italy-Veneto:Corvina, Rondinella, Molinara  \n",
       "4                          Germany-Mosel:Riesling  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data[\"train\"][\"keywords\"])\n",
    "\n",
    "train_vectors = vectorizer.transform(data[\"train\"][\"keywords\"])\n",
    "test_vectors = vectorizer.transform(data[\"test\"][\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer #features: 18261\n",
      "Vectorizer features: ['agoston', 'agreeability', 'agreeable', 'agressive', 'agricoltori', 'agriculture', 'agrinatura', 'agro', 'agua', 'aguia', 'agustin', 'ahi', 'aid', 'aidil', 'aids', 'aiken', 'aims', 'aiolo', 'air', 'airborne', 'aires', 'airfield', 'airiness', 'airing', 'airs', 'airtime', 'airy', 'airén', 'aix', 'aka', 'akin', 'al', 'alabaster', 'alain', 'alamos', 'alan', 'alana', 'alance', 'alarid', 'alarming', 'alaska', 'alastro', 'alayt', 'alazan', 'alba', 'alban', 'albana', 'albanello', 'albar', 'albarino', 'albariño', 'albarossa', 'albe', 'albeggio', 'albera', 'alberdi', 'albert', 'alberta', 'alberto', 'albola', 'alcamo', 'alcantara', 'alchemist', 'alchemy', 'alcholic', 'alcineo', 'alcohol', 'alcoholic', 'alconte', 'aldegheri', 'alder', 'alderbrook', 'ale', 'aleatico', 'alejandro', 'alella', 'alene', 'alentejano', 'alentejo', 'aleramico', 'alert', 'alessandro', 'alessano', 'alessio', 'alex', 'alexander', 'alexandra', 'alexandre', 'alexandria', 'alexandrine', 'alexia', 'alexis', 'alfalfa', 'alfonso', 'alfred', 'alfredo', 'alfresco', 'alfrocheiro', 'aliança', 'alicante']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rqiu/Library/Caches/pypoetry/virtualenvs/sommelier-app-LnLhopHO-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizer #features:\", len(vectorizer.get_feature_names()))\n",
    "print(\"Vectorizer features:\", vectorizer.get_feature_names()[500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a custom function to evaluate the list of models:\n",
    "\n",
    "\n",
    "def top_5_acc(estimator, X, y):\n",
    "    try:\n",
    "        y_pred_proba = estimator.predict_proba(X)\n",
    "    except AttributeError:\n",
    "        y_pred_proba = estimator.decision_function(X)\n",
    "    return top_k_accuracy_score(y, y_pred_proba, k=5)\n",
    "\n",
    "\n",
    "def eval_model(model, X, y, n_jobs=-1):\n",
    "    \"\"\"Evaluate a list of models using cross-validation.\n",
    "\n",
    "    Args:\n",
    "        models (dict): A dictionary of models to evaluate.\n",
    "        X (array-like): Training data.\n",
    "        y (array-like): Training labels.\n",
    "\n",
    "    Returns:\n",
    "        scores (list): Dictionary of scores (another dict) for each model.\n",
    "    \"\"\"\n",
    "    # for name, model in tqdm(models.items()):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_scores = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=top_5_acc,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[Train] Top-5 prediction mean accuracy: {cv_scores['train_score'].mean():.3f} (+/- {cv_scores['train_score'].std() * 2:.3f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[Test] Top-5 prediction mean accuracy: {cv_scores['test_score'].mean():.3f} (+/- {cv_scores['test_score'].std() * 2:.3f})\"\n",
    "    )\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Create a dictionary to collect model metrics\n",
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.598 (+/- 0.002)\n",
      "[Test] Top-5 prediction mean accuracy: 0.551 (+/- 0.002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.9s finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate naïve bayes\n",
    "nb = MultinomialNB()\n",
    "scores[\"nb\"] = eval_model(nb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.774 (+/- 0.011)\n",
      "[Test] Top-5 prediction mean accuracy: 0.487 (+/- 0.016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   49.9s finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate perceptron\n",
    "perceptron = Perceptron(random_state=random_state, early_stopping=True)\n",
    "scores[\"perceptron\"] = eval_model(\n",
    "    perceptron, train_vectors, data[\"train\"][\"region_variety\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.970 (+/- 0.001)\n",
      "[Test] Top-5 prediction mean accuracy: 0.626 (+/- 0.006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate linear SVM\n",
    "svm = LinearSVC(random_state=random_state)\n",
    "scores[\"svm\"] = eval_model(svm, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.410 (+/- 0.005)\n",
      "[Test] Top-5 prediction mean accuracy: 0.334 (+/- 0.005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.5s finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate decision tree\n",
    "tree = DecisionTreeClassifier(random_state=random_state, max_depth=20)\n",
    "scores[\"tree\"] = eval_model(tree, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate adaboost\n",
    "# ada = AdaBoostClassifier(random_state=random_state, n_estimators=100)\n",
    "# scores[\"ada\"] = eval_model(ada, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate gradient boosting\n",
    "# gb = GradientBoostingClassifier(random_state=random_state, n_estimators=10, max_depth=5)\n",
    "# scores[\"gb\"] = eval_model(gb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate XGBoost\n",
    "# xgb = XGBClassifier(random_state=random_state, n_estimators=100, max_depth=20, n_jobs=-1)\n",
    "# scores[\"xgb\"] = eval_model(xgb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "# Encode np.array to JSON\n",
    "\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "with open(\"../models/scores.json\", \"w\") as f:\n",
    "    json.dump(scores, f, cls=NumpyArrayEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some thoughts on stacking strategies:\n",
    "\n",
    "1. To align with our BERT model, we intentionally selected the top 5 prediction accuracy as our evaluation metrics in training. This is a little tricky. The `make_scorer()` function takes two parameters `needs_proba` and `needs_threshold` which are both `False` by default. But for specific models, we need to turn the parameters on to calculate the similar \n",
    "2. We discarded the ensemble models in stacking, since the training time of ensemble models in our case is comparatively long due to the size and feature number of the dataset.\n",
    "\n",
    "We managed to show the efforts, and would focus more on the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# level0 = list()\n",
    "# level0.append((\"nb\", nb))\n",
    "# level0.append((\"perceptron\", perceptron))\n",
    "# level0.append((\"svm\", svm))\n",
    "# # level0.append((\"tree\", tree)) # the accuracy is not ideal\n",
    "# # level0.append((\"ada\", ada)) # the accuracy is too low, plus the parameter turning is quite time-consuming in this stage\n",
    "# level0.append((\"gb\", gb))\n",
    "# level0.append((\"xgb\", xgb))\n",
    "\n",
    "# level1 = XGBClassifier(random_state=random_state)\n",
    "# model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1, passthrough=False)\n",
    "# model.fit(train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sommelier-app-LnLhopHO-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30804d2f67ffdaea00cb5c53926dce42897aabfd7d02ebe37057f3b56b5c9f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
