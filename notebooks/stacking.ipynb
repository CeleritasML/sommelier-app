{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords and labels\n",
    "\n",
    "data = {\n",
    "    \"train\": pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\"../data/wine_keywords_train.csv\"),\n",
    "            pd.read_csv(\"../data/wine_keywords_val.csv\"),\n",
    "        ]\n",
    "    ).dropna(),\n",
    "    \"test\": pd.read_csv(\"../data/wine_keywords_test.csv\").dropna(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>region_variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>core adequate acidity moderate extraction medi...</td>\n",
       "      <td>France-Languedoc-Roussillon:Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complexity varietal character black plum light...</td>\n",
       "      <td>US-California:Merlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rhubarb cranberry fruit red apple light simple...</td>\n",
       "      <td>US-Oregon:Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impressive fullness ripeness black cherry leat...</td>\n",
       "      <td>Italy-Veneto:Corvina, Rondinella, Molinara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dusty tones mineral saffron pollen concentrate...</td>\n",
       "      <td>Germany-Mosel:Riesling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            keywords  \\\n",
       "0  core adequate acidity moderate extraction medi...   \n",
       "1  complexity varietal character black plum light...   \n",
       "2  rhubarb cranberry fruit red apple light simple...   \n",
       "3  impressive fullness ripeness black cherry leat...   \n",
       "4  dusty tones mineral saffron pollen concentrate...   \n",
       "\n",
       "                                   region_variety  \n",
       "0  France-Languedoc-Roussillon:Cabernet Sauvignon  \n",
       "1                            US-California:Merlot  \n",
       "2                            US-Oregon:Pinot Noir  \n",
       "3      Italy-Veneto:Corvina, Rondinella, Molinara  \n",
       "4                          Germany-Mosel:Riesling  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data[\"train\"][\"keywords\"])\n",
    "\n",
    "train_vectors = vectorizer.transform(data[\"train\"][\"keywords\"])\n",
    "test_vectors = vectorizer.transform(data[\"test\"][\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer #features: 18261\n",
      "Vectorizer features: ['agoston', 'agreeability', 'agreeable', 'agressive', 'agricoltori', 'agriculture', 'agrinatura', 'agro', 'agua', 'aguia', 'agustin', 'ahi', 'aid', 'aidil', 'aids', 'aiken', 'aims', 'aiolo', 'air', 'airborne', 'aires', 'airfield', 'airiness', 'airing', 'airs', 'airtime', 'airy', 'airén', 'aix', 'aka', 'akin', 'al', 'alabaster', 'alain', 'alamos', 'alan', 'alana', 'alance', 'alarid', 'alarming', 'alaska', 'alastro', 'alayt', 'alazan', 'alba', 'alban', 'albana', 'albanello', 'albar', 'albarino', 'albariño', 'albarossa', 'albe', 'albeggio', 'albera', 'alberdi', 'albert', 'alberta', 'alberto', 'albola', 'alcamo', 'alcantara', 'alchemist', 'alchemy', 'alcholic', 'alcineo', 'alcohol', 'alcoholic', 'alconte', 'aldegheri', 'alder', 'alderbrook', 'ale', 'aleatico', 'alejandro', 'alella', 'alene', 'alentejano', 'alentejo', 'aleramico', 'alert', 'alessandro', 'alessano', 'alessio', 'alex', 'alexander', 'alexandra', 'alexandre', 'alexandria', 'alexandrine', 'alexia', 'alexis', 'alfalfa', 'alfonso', 'alfred', 'alfredo', 'alfresco', 'alfrocheiro', 'aliança', 'alicante']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rqiu/Library/Caches/pypoetry/virtualenvs/sommelier-app-TihBwtmf-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizer #features:\", len(vectorizer.get_feature_names()))\n",
    "print(\"Vectorizer features:\", vectorizer.get_feature_names()[500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a custom function to evaluate the list of models:\n",
    "\n",
    "\n",
    "def top_5_acc(estimator, X, y):\n",
    "    try:\n",
    "        y_pred_proba = estimator.predict_proba(X)\n",
    "    except AttributeError:\n",
    "        y_pred_proba = estimator.decision_function(X)\n",
    "    return top_k_accuracy_score(y, y_pred_proba, k=5)\n",
    "\n",
    "\n",
    "def eval_model(model, X, y, n_jobs=-1):\n",
    "    \"\"\"Evaluate a list of models using cross-validation.\n",
    "\n",
    "    Args:\n",
    "        models (dict): A dictionary of models to evaluate.\n",
    "        X (array-like): Training data.\n",
    "        y (array-like): Training labels.\n",
    "\n",
    "    Returns:\n",
    "        scores (list): Dictionary of scores (another dict) for each model.\n",
    "    \"\"\"\n",
    "    # for name, model in tqdm(models.items()):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_scores = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=top_5_acc,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[Train] Top-5 prediction mean accuracy: {cv_scores['train_score'].mean():.3f} (+/- {cv_scores['train_score'].std() * 2:.3f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[Test] Top-5 prediction mean accuracy: {cv_scores['test_score'].mean():.3f} (+/- {cv_scores['test_score'].std() * 2:.3f})\"\n",
    "    )\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Create a dictionary to collect model metrics\n",
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.0s remaining:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.598 (+/- 0.002)\n",
      "[Test] Top-5 prediction mean accuracy: 0.551 (+/- 0.002)\n"
     ]
    }
   ],
   "source": [
    "# evaluate naïve bayes\n",
    "nb = MultinomialNB()\n",
    "scores[\"nb\"] = eval_model(nb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   44.6s remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.774 (+/- 0.011)\n",
      "[Test] Top-5 prediction mean accuracy: 0.487 (+/- 0.016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   45.2s finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate perceptron\n",
    "perceptron = Perceptron(random_state=random_state, early_stopping=True)\n",
    "scores[\"perceptron\"] = eval_model(\n",
    "    perceptron, train_vectors, data[\"train\"][\"region_variety\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   36.0s remaining:   53.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# evaluate linear SVM\u001b[39;00m\n\u001b[1;32m      2\u001b[0m svm \u001b[38;5;241m=\u001b[39m LinearSVC(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m----> 3\u001b[0m scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregion_variety\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 31\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, X, y, n_jobs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# for name, model in tqdm(models.items()):\u001b[39;00m\n\u001b[1;32m     30\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m---> 31\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_5_acc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] Top-5 prediction mean accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Test] Top-5 prediction mean accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sommelier-app-TihBwtmf-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sommelier-app-TihBwtmf-py3.9/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sommelier-app-TihBwtmf-py3.9/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sommelier-app-TihBwtmf-py3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate linear SVM\n",
    "svm = LinearSVC(random_state=random_state)\n",
    "scores[\"svm\"] = eval_model(svm, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.6s remaining:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Top-5 prediction mean accuracy: 0.410 (+/- 0.005)\n",
      "[Test] Top-5 prediction mean accuracy: 0.334 (+/- 0.005)\n"
     ]
    }
   ],
   "source": [
    "# evaluate decision tree\n",
    "tree = DecisionTreeClassifier(random_state=random_state, max_depth=20)\n",
    "scores[\"tree\"] = eval_model(tree, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate adaboost\n",
    "# ada = AdaBoostClassifier(random_state=random_state, n_estimators=20)\n",
    "# scores[\"ada\"] = eval_model(ada, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate gradient boosting\n",
    "# gb = GradientBoostingClassifier(random_state=random_state, n_estimators=10, max_depth=5)\n",
    "# scores[\"gb\"] = eval_model(gb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate XGBoost\n",
    "# xgb = XGBClassifier(random_state=random_state, n_estimators=10, max_depth=10, n_jobs=-1)\n",
    "# scores[\"xgb\"] = eval_model(xgb, train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some thoughts on stacking strategies:\n",
    "\n",
    "1. To align with our BERT model, we intentionally selected the top 5 prediction accuracy as our evaluation metrics in training. This is a little tricky. The `make_scorer()` function takes two parameters `needs_proba` and `needs_threshold` which are both `False` by default. But for specific models, we need to turn the parameters on to calculate the similar \n",
    "2. We discarded the ensemble models in stacking, since the training time of ensemble models in our case is comparatively long due to the size and feature number of the dataset.\n",
    "\n",
    "We managed to show the efforts, and would focus more on the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "level0 = list()\n",
    "level0.append((\"nb\", nb))\n",
    "level0.append((\"perceptron\", perceptron))\n",
    "level0.append((\"svm\", svm))\n",
    "level0.append((\"tree\", tree))\n",
    "# level0.append((\"ada\", ada)) # the accuracy is too low, plus the parameter turning is quite time-consuming in this stage\n",
    "# level0.append((\"gb\", gb))\n",
    "# level0.append((\"xgb\", xgb))\n",
    "\n",
    "level1 = LinearSVC(random_state=random_state)\n",
    "stacked = StackingClassifier(\n",
    "    estimators=level0, final_estimator=level1, cv=5, n_jobs=-1, passthrough=False\n",
    ")\n",
    "# stacked.fit(train_vectors, data[\"train\"][\"region_variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "model_summary = {\n",
    "    \"models\": [nb, perceptron, svm, tree, stacked],\n",
    "    \"scores\": scores,\n",
    "}\n",
    "\n",
    "with open(\"../models/model_summary.pkl\", \"wb\") as f:\n",
    "    dill.dump(model_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from json import JSONEncoder\n",
    "\n",
    "# # Encode np.array to JSON\n",
    "\n",
    "# class NumpyArrayEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "# with open(\"../models/scores.json\", \"w\") as f:\n",
    "#     json.dump(scores, f, cls=NumpyArrayEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sommelier-app-LnLhopHO-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30804d2f67ffdaea00cb5c53926dce42897aabfd7d02ebe37057f3b56b5c9f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
